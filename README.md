[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/sRMOJrsa)



PROCESS

This binary classificiation problem was very similar to our hackathon project so we found it fairly easy to navigate. After going through the tutorial, similar submissions and our previous project we were able to break down the project into these simple steps which we used to accomplish our task.
- Import necessary libraries
- Import the respective train and test datasets.
- Explore the datasets.
- Clean the train dataset. Dropping duplicates is done here to ensure data consistency and quality.
- Plot wordclouds to check the frequency of words in both the 'disaster' and 'non-disaster' class.
- Preprocess the cleaned dataset.
- Train 3 different models on the  preprocessed dataset and compare their metrics,to get the best one.
- Use the selected model to classify the data in the test dataset and map it to a .csv file for submission






FINDINGS

After testing on 3 different models, alogistic regression model, a naive bayes model, and a Linear Support Vector Classifier the results showed that the logistic regression model had the highest accuracy, proving that it is one of the best models for binary classification.


CHALLENGES

We had a little trouble setting up the jupyter notebook but we quickly learned how to use it and our journey was smooth sailing from there.

